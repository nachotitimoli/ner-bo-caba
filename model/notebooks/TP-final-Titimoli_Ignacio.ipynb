{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7233b500-56df-43f4-a08e-76c64b4d0cc3",
   "metadata": {},
   "source": [
    "## Trabajo práctico final | Ignacio Titimoli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e91e5-6706-404b-bed6-b29d18910ddd",
   "metadata": {},
   "source": [
    "## Conversión de archivos .pdf a .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c371e5-1222-4c71-896f-7765ff2895f2",
   "metadata": {},
   "source": [
    "Comenzaremos por importar las librerías requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b338af15-13e3-4a41-bdab-dd4efdeb11e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac40db-ec8f-4358-9387-5b29d6ae1106",
   "metadata": {},
   "source": [
    "A continuación, setearemos el directorio de trabajo desde el cual tomaremos los archivos que necesitamos convertir a texto.\n",
    "\n",
    "El código \"loopea\" entre todos los archivos .pdf guardados en el directorio predefinido.\n",
    "Dentro del loop, el archivo PDF es aperturado en formato binario, utilizando la función `open`.\n",
    "\n",
    "Utilizaremos `PyPDF2.PdfReader` para leer los archivos PDF, y el contenido será guardado dentro de la variable `pdf_reader`.\n",
    "La función `extract_text()` es utilizada para que, en cada página del documento, extraiga el texto que encuentre.\n",
    "Lo extraído se inserta dentro de la variable `text`.\n",
    "\n",
    "A continuación, se crea un nuevo archivo de texto con el mismo nombre que figura en el pdf mediante `os.path.splitext()`, que parte el nombre del archivo y su extensión.\n",
    "\n",
    "Finalmente, el texto extraído es escrito en el nuevo archivo de texto a partir de la función `write()`.\n",
    "Luego, tanto el archivo PDF como el archivo de texto, son cerrados.\n",
    "\n",
    "[Fuente](https://medium.com/mlearning-ai/extracting-text-from-multiple-pdf-files-with-python-and-pypdf2-b37f08ef728d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516eb357-d951-4f43-baa3-56a004671c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_dir = os.getcwd()\n",
    "\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_file = open(os.path.join(pdf_dir, filename), 'rb')\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text = ''\n",
    "\n",
    "        for i in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[i]\n",
    "            text += page.extract_text()\n",
    "\n",
    "        txt_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "        txt_file = open(os.path.join(pdf_dir, txt_filename), 'w')\n",
    "\n",
    "        txt_file.write(text)\n",
    "\n",
    "        pdf_file.close()\n",
    "        txt_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3045d8a9-d7e2-4ed2-a329-3d1f73b213df",
   "metadata": {},
   "source": [
    "A los efectos de poder realizar un taggeo de los datos en forma más rápida (aunque menos precisa), trabajeremos con una muestra del .txt obtenido (\"BO-5350_2.txt\"), que solo contiene una resolución dentro de la gran cantidad de resoluciones publicadas en el Boletín Oficial que utilizaremos como input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67d1f4-fd36-4ecd-b47d-36a1e744af3e",
   "metadata": {},
   "source": [
    "## Implementación de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39201371-a478-4ecb-8048-a45a74c9c7ae",
   "metadata": {},
   "source": [
    "Con ayuda de lo dispuesto en la siguiente [WEB](https://aws.amazon.com/es/blogs/machine-learning/developing-ner-models-with-amazon-sagemaker-ground-truth-and-amazon-comprehend/), implementaremos nuestro modelo para el etiquetado de entidades dentro de nuestra data.\n",
    "La intención final es poder crear el siguiente flujo:\n",
    "\n",
    "<img src=\"img/ner.jpg\">\n",
    "\n",
    "El proceso end-to-end consistirá en:\n",
    "<ol>\n",
    "    <li> Cargar el archivo (muestra de un Boletín Oficial) en S3 (punto 1).</li>\n",
    "    <li> Utilizar el template mencionado previamente para generar la infraestructura necesaria en AWS (función Lambda y creación de buckets en S3) para llevar adelante este proceso. Se utilizará para lo dicho AWS CloudFormation. </li>\n",
    "    <li> Crear un equipo de trabajo privado y utilizar NER dentro de Amazon SageMaker (Ground Truth) para etiquetar nuestra data (puntos 2 y 3).</li>\n",
    "    <li> Realizar el trabajo de taggeo de nuestra data en Ground Truth de acuerdo con las entidades que son de nuestro interés (puntos 4a y b).</li>\n",
    "    <li> Mediante el archivo manifiesto, transformar las etiquetas generadas sobre nuestra data input a un archivo en formato .csv para que estas puedan ser entrenadas dentro de Amazon Comprehend (puntos 5a y b).</li>\n",
    "    <li> En Amazon Comprehend, lanzar un trabajo customizado de entrenamiento con NER, utilizando el dataset con entidades generado por la AWS Lambda (puntos 6a y b).</li>\n",
    "    <li> Evaluar los resultados obtenidos.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563fd732-d515-4cd1-a73f-0a938b77c0af",
   "metadata": {},
   "source": [
    "### Pipeline de conversión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059aee4-fb5f-4f29-87f1-2f9a4e8fb0c3",
   "metadata": {},
   "source": [
    "Tomando como parámetro el siguiente [archivo YAML](https://aws-ml-blog.s3.amazonaws.com/artifacts/blog-groundtruth-comprehend-ner/cfn/cfn.yaml), iniciaremos dentro de CloudFormation el template que nos permitirá crear el bucket en S3, crear también la función Lambda y configurar la relación entre el bucket y dicha función para dispararla automáticamente cada vez que se detecte la llegada de archivos dentro de la carpeta `output.manifest`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81588ff0-91b9-4493-b7f0-af6ee4a87e94",
   "metadata": {},
   "source": [
    "En nuestro caso, hemos creado el stack \"ner-demo-lv\" que, como mencionamos, convertirá a través de una función Lambda el archivo manifiesto aumentado generado en SageMaker Ground Truth a un formato reconocido por Amazon Comprehend para poder efectuar el entrenamiento.\n",
    "\n",
    "<img src=\"img/cloud_formation.png\">\n",
    "<img src=\"img/cloud_formation2.png\">\n",
    "<img src=\"img/cloud_formation3.png\">\n",
    "<img src=\"img/cloud_formation4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0c262-470d-4cfe-aa71-3f33488706f3",
   "metadata": {},
   "source": [
    "### Carga de archivos en S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef7f941-af8e-454c-a6fa-6e36ef53f87e",
   "metadata": {},
   "source": [
    "Cargaremos, dentro del bucket de S3 generado con CloudFormation, nuestra data cruda.\n",
    "\n",
    "Como hemos mencionado, utilizaremos una muestra de nuestro Boletín Oficial (\"BO_5350_2\".txt), para poder trabajar con un corpus de texto más pequeño que nos ahorre tiempo al taggear las entidades.\n",
    "\n",
    "<img src=\"img/s3.png\">\n",
    "<img src=\"img/s3_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6579d86d-225b-49b6-a68a-933ca02b8821",
   "metadata": {},
   "source": [
    "### Ejecución del trabajo de etiquetado de entidades con NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3232e5-769d-4b43-9356-5b34de2e8bb1",
   "metadata": {},
   "source": [
    "#### Crear un equipo de trabajo privado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b2e63f-cb1e-4de8-a3a4-48712530657d",
   "metadata": {},
   "source": [
    "Dentro de SageMaker, crearemos un equipo de trabajo privado que nos incluya a nosotros mismos. Este es el puntapié para poder, posteriormente, generar el trabajo de etiquetado y reconocimiento de entidades sobre nuestra data de input.\n",
    "\n",
    "<img src=\"img/gt_equipoprivado.png\">\n",
    "<img src=\"img/gt_equipoprivado2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd7432-7069-4aa2-ba9d-a80eb70b8792",
   "metadata": {},
   "source": [
    "#### Creación del archivo manifiesto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e9b4c-5e81-45fe-8759-1bacd99c06d8",
   "metadata": {},
   "source": [
    "Generado el entorno de trabajo, utilizaremos el módulo de Ground Truth dentro de SageMaker para crear un trabajo de etiquetado.\n",
    "Con este paso estaremos realizando:\n",
    "\n",
    "<ol>\n",
    "    <li> La creación del archivo manifiesto (que luego utilizaremos en formato json).</li>\n",
    "    <li> Indicaremos desde dónde debe tomarse la data input. </li>\n",
    "    <li> Indicaremos dónde deberá almacenarse la salida. </li>\n",
    "    <li> Asignaremos el listado de entidades con el cual trabajeremos. </li>\n",
    "</ol>\n",
    "\n",
    "<img src=\"img/label_job_resume.png\">\n",
    "\n",
    "En el resumen de nuestro label job podemos ver:\n",
    "\n",
    "- La ubicación en nuestro bucket de S3 del conjunto de datos de entrada.\n",
    "- La ubicación en nuestro bucket de S3 del conjunto de datos de salida.\n",
    "\n",
    "Por un error en la configuración, almacenamos la salida en la misma carpeta que la entrada (raw). Sin embargo, el archivo con los datos de entrada es el siguiente (aquí pueden verse las 186 sentencias):\n",
    "\n",
    "<img src=\"img/label_job_entries.png\">\n",
    "\n",
    "La carpeta de salida (\"etiqueta-boletin-3\"), contiene a su vez cuatro subcarpetas. Una de ellas es \"manifests\", la cual, a su vez, dentro de la carpeta \"output\", contiene el archivo output.manifest.\n",
    "\n",
    "<img src=\"img/label_job_output_folder.png\">\n",
    "\n",
    "Este es el archivo output.manifest.\n",
    "\n",
    "<img src=\"img/output_manifest.png\">\n",
    "\n",
    "Y este es un ejemplo de una línea del archivo, en donde para el recurso \"RESOLUCIÓN N.° 49/UPEJOL/18\", se definió identificar a \"49/UPEJOL/18\" con la entidad \"resolución\":\n",
    "\n",
    "{\"source\":\"RESOLUCIÓN N.° 49/UPEJOL/18  \",\"etiqueta-boletin-3\":{\"annotations\":{\"labels\":[{\"label\":\"Date\",\"shortDisplayName\":\"Dat\"},{\"label\":\"Resolution\",\"shortDisplayName\":\"R\"},{\"label\":\"Type\",\"shortDisplayName\":\"T\"},{\"label\":\"Motivo\",\"shortDisplayName\":\"M\"},{\"label\":\"Awarded company\",\"shortDisplayName\":\"A\"},{\"label\":\"Department\",\"shortDisplayName\":\"I\"},{\"label\":\"Amount\",\"shortDisplayName\":\"A\"}],\"entities\":[{\"label\":\"Resolution\",\"startOffset\":15,\"endOffset\":27}]}},\"etiqueta-boletin-3-metadata\":{\"job-name\":\"labeling-job/etiqueta-boletin-3\",\"type\":\"groundtruth/text-span\",\"creation-date\":\"2023-10-16T11:28:08.355345\",\"human-annotated\":\"yes\",\"entities\":[{\"confidence\":0}]}}\n",
    "\n",
    "\n",
    "\n",
    "Como puede observarse, en primera instancia habíamos intentado procesar la data completa de nuestro boletín, pero el servicio reconoció 41.810 sentencias para etiquetar. De este modo, al achicar nuestra data de input, solo taggeamos 186.\n",
    "\n",
    "<img src=\"img/label_job.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31428d-1a32-4f41-99d1-e24c7f1540cc",
   "metadata": {},
   "source": [
    "#### Etiquetar nuestra data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c9a4f-06ee-4c37-8735-f2daf97bb13c",
   "metadata": {},
   "source": [
    "Dentro del entorno privado generado en primera instancia, realizaremos el trabajo de etiquetado de nuestra data.\n",
    "\n",
    "<img src=\"img/etiquetar_nuestra_data.png\">\n",
    "\n",
    "En el ejemplo anterior, se observa cómo funciona el proceso de etiquetado y matcheo de frases y palabras dentro del corpus de texto con las entidades predefinidas. En este caso, asignamos a la empresa \"POSTRES BALCARCE S.A.\" con una \"awarded company\", es decir, con una \"empresa adjudicataria\" en un proceso licitatorio.\n",
    "\n",
    "Aquí mostramos cómo queda configurado el taggeo definitivo de nuestros datos:\n",
    "\n",
    "<img src=\"img/cjto_datos_etiquetados.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587e725-337e-4d9d-8975-bc9745c4d2eb",
   "metadata": {},
   "source": [
    "Como fue mencionado, el template de CloudFormation configuró el bucket de S3 para correr una función Lambda cada vez que existan objetos nuevos dentro de la dirección manifests/output/output.manifest.\n",
    "\n",
    "La función Lambda carga el archivo manifiesto aumentado y lo convierte en dos nuevos archivos (uno .csv y otro .txt).\n",
    "\n",
    "El archivo .csv contiene las anotaciones específicas realizadas sobre la data y el .txt es el archivo puro que fue cargado para hacer el reconocimiento y taggeo de entidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5d29c-fd47-432a-a20d-0e7cd5773980",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea5597-4321-4902-b933-03dc7a50acf7",
   "metadata": {},
   "source": [
    "Finalmente, entrenaremos nuestro modelo con Amazon Comprehend.\n",
    "\n",
    "Para poder hacerlo, Comprehend \"exige\" una serie de atributos en nuestra data. Uno de ellos es la longitud. Si bien nosotros habíamos definido 7 entidades (fecha, resolución, tipo de resolución, motivo de contratación, empresa adjudicataria, importe adjudicado y ministerio), en nuestro corpus de datos no habíamos podido definir la suficiente cantidad de veces cada una de ellas. Por ejemplo, la fecha había sido definida una sola vez (porque tomamos como input solo una resolución de las tantas que figuran dentro del boletín). En este sentido, Comprehend requiere la repetición de una entidad en al menos 25 oportunidades para poder efectuar el trabajo. Las dos únicas entidades que se repetían al menos 25 veces dentro de nuestro corpus de texto eran \"awarded company\" (empresa adjudicataria) y \"motivo de contratación\". Por esa razón, solo entrenamos nuestro modelo basándonos en estas entidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5664b-8d7e-4403-a9c4-3919f66d1b49",
   "metadata": {},
   "source": [
    "Para comenzar con el proceso de entrenamiento:\n",
    "\n",
    "- En Comprehend creamos un trabajo de entrenamiento customizado, en el cual definimos las dos entidades antes mencionadas.\n",
    "- Además, se definieron las carpetas dentro de nuestro bucket de S3 para tomar el archivo con las anotaciones y también los archivos que deberían considerarse como input/documentos de procesamiento.\n",
    "- Se creó un rol específico para poder acceder a los buckets y poder realizar este ejercicio.\n",
    "- Finalmente, se entrenó el modelo. El proceso demoró 10 minutos y obtuvo un F1-score de 70.96\n",
    "\n",
    "<img src=\"img/cer.png\">\n",
    "<img src=\"img/cer2.png\">\n",
    "<img src=\"img/cer3.png\">\n",
    "<img src=\"img/cer4.png\">\n",
    "<img src=\"img/cer5.png\">\n",
    "<img src=\"img/cer6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe22ba9-ea86-415c-b27c-3266d31622e0",
   "metadata": {},
   "source": [
    "Terminado el entrenamiento, decidimos utilizar nuestro modelo para etiquetar data nueva, con la cual nunca habíamos interactuado. Es decir, probamos nuestro modelo.\n",
    "\n",
    "Para ello, utilizamos como ejemplo al Boletín Oficial 5351, correspondiente al día 11 de abril de 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ccbac-bd85-4749-8394-983844ff5cf6",
   "metadata": {},
   "source": [
    "Ejecutamos un proceso de análisis, donde definimos el bucket de S3 desde el cual tomar la data, también  en donde almacenar los resultados, generamos los roles IAM para poder llevar adelante el procedimiento y, por sobre todas las cosas, definimos el nombre del modelo que debía considerar para llevar adelante la tarea (en este caso, \"my-ner-boletin-02\").\n",
    "\n",
    "<img src=\"img/analisis.png\">\n",
    "<img src=\"img/analisis2.png\">\n",
    "\n",
    "El job corrió durante 18 minutos y arrojó un archivo en formato .tar.gz que descomprimimos para acceder a un json, que exploraremos a continuación.\n",
    "\n",
    "<img src=\"img/analisis3.png\">\n",
    "<img src=\"img/analisis4.png\">\n",
    "\n",
    "Este es el archivo final, que obtuvimos luego de descomprimir el .tar.gz que descargamos desde S3.\n",
    "\n",
    "<img src=\"img/analisis5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c3326-ec18-4193-8b68-60a5c61455c7",
   "metadata": {},
   "source": [
    "### Exploración sobre la data generada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932d5a9-59fd-4829-b086-69a46151cd6d",
   "metadata": {},
   "source": [
    "Comenzamos por importar la librería de pandas y por leer nuestro archivo (que guardamos en formato json), con la respuesta de nuestro modelo. El mismo lo convertiremos en un dataframe de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8494350-7f9a-4242-af9e-1c0aad436422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('json/output.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1beb2b-d8f1-4c89-a4d1-098dfb61e6cb",
   "metadata": {},
   "source": [
    "Analizamos las primeras dos filas de nuestro archivo. Como puede verse, hay muchas líneas de texto que no tienen una entidad reconocida, y por eso figuran con la primera columna vacía. Sin embargo, hay otras para las que sí logró detectar información.\n",
    "\n",
    "La misma puede observarse en un formato poco amigable, por lo que iniciaremos un proceso de readaptación de la data para poder trabajar con ella de forma adecuada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9c6868-0c54-494b-9966-c5a1a5bf4b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>File</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>BO-5351.txt</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>BO-5351.txt</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entities         File  Line\n",
       "0       []  BO-5351.txt    46\n",
       "1       []  BO-5351.txt    47"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe296a6-6207-4237-9084-7b4b3f470028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entities    [{'BeginOffset': 0, 'EndOffset': 10, 'Score': ...\n",
       "File                                              BO-5351.txt\n",
       "Line                                                      108\n",
       "Name: 61, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linea del archivo para la que sí encontró entidades\n",
    "\n",
    "df.iloc[61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5128be5-020e-47b0-976a-12c9f85dcf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BeginOffset  EndOffset     Score                             Text  \\\n",
      "0               0         10  0.571418                       Ministerio   \n",
      "1              19         50  0.995079  JUEGOS OLÍMPICOS DE LA JUVENTUD   \n",
      "2               0         10  0.728365                       Ministerio   \n",
      "3               0         10  0.567420                       Ministerio   \n",
      "4               0         10  0.782546                       Ministerio   \n",
      "...           ...        ...       ...                              ...   \n",
      "3732            1          7  0.842248                           603130   \n",
      "3733           44         50  0.814382                           603210   \n",
      "3734            0          7  0.876399                          (603310   \n",
      "3735           99        129  0.913092   C I U D A D DE B U E N O S A I   \n",
      "3736           15         41  0.951447       LOS JUEGOS OLÍMPICOS DE LA   \n",
      "\n",
      "                 Type  \n",
      "0     AWARDED COMPANY  \n",
      "1              MOTIVO  \n",
      "2     AWARDED COMPANY  \n",
      "3     AWARDED COMPANY  \n",
      "4     AWARDED COMPANY  \n",
      "...               ...  \n",
      "3732  AWARDED COMPANY  \n",
      "3733  AWARDED COMPANY  \n",
      "3734  AWARDED COMPANY  \n",
      "3735  AWARDED COMPANY  \n",
      "3736           MOTIVO  \n",
      "\n",
      "[3737 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# En una lista almacenamos los DataFrames en forma aplanada\n",
    "datos_aplanados = []\n",
    "\n",
    "# Iteramos a través de las filas de nuestro DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if 'Entities' in row:\n",
    "        aplanado = pd.json_normalize(row['Entities'])\n",
    "        datos_aplanados.append(aplanado)\n",
    "\n",
    "# Concatenamos los DataFrames aplanados en uno solo\n",
    "df_2 = pd.concat(datos_aplanados, ignore_index=True)\n",
    "\n",
    "# Inspeccionamos el DataFrame final (df_2)\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a18ffc5-a464-458d-8982-a543b6ed8f37",
   "metadata": {},
   "source": [
    "Inspeccionamos las primeras 15 filas, para asegurarnos que las entidades de \"AWARDED COMPANY\" y \"MOTIVO\" hayan sido correctamente asignadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933baa02-6130-486c-af59-3e4e7ef9a9d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.571418</td>\n",
       "      <td>Ministerio</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>0.995079</td>\n",
       "      <td>JUEGOS OLÍMPICOS DE LA JUVENTUD</td>\n",
       "      <td>MOTIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.728365</td>\n",
       "      <td>Ministerio</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.567420</td>\n",
       "      <td>Ministerio</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.782546</td>\n",
       "      <td>Ministerio</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.878687</td>\n",
       "      <td>Ministerio</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>78</td>\n",
       "      <td>0.912655</td>\n",
       "      <td>Servicios Integrales de Alimentación SA - Arki...</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "      <td>0.859064</td>\n",
       "      <td>UTE</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>0.938471</td>\n",
       "      <td>Comahue Seguridad Privada SA</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>0.862666</td>\n",
       "      <td>Líderes Consultores de Seguridad SRL</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.571418</td>\n",
       "      <td>Ministerio</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>0.773930</td>\n",
       "      <td>Custos Seguridad</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>0.804919</td>\n",
       "      <td>X Protection SRL</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.890798</td>\n",
       "      <td>Cooperativa de Trabajo Cruz de Malta Ltda</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.666218</td>\n",
       "      <td>Borguards SRL</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BeginOffset  EndOffset     Score  \\\n",
       "0             0         10  0.571418   \n",
       "1            19         50  0.995079   \n",
       "2             0         10  0.728365   \n",
       "3             0         10  0.567420   \n",
       "4             0         10  0.782546   \n",
       "5             0         10  0.878687   \n",
       "6            27         78  0.912655   \n",
       "7            81         84  0.859064   \n",
       "8            27         55  0.938471   \n",
       "9            27         63  0.862666   \n",
       "10            0         10  0.571418   \n",
       "11           61         77  0.773930   \n",
       "12           61         77  0.804919   \n",
       "13            0         41  0.890798   \n",
       "14            0         13  0.666218   \n",
       "\n",
       "                                                 Text             Type  \n",
       "0                                          Ministerio  AWARDED COMPANY  \n",
       "1                     JUEGOS OLÍMPICOS DE LA JUVENTUD           MOTIVO  \n",
       "2                                          Ministerio  AWARDED COMPANY  \n",
       "3                                          Ministerio  AWARDED COMPANY  \n",
       "4                                          Ministerio  AWARDED COMPANY  \n",
       "5                                          Ministerio  AWARDED COMPANY  \n",
       "6   Servicios Integrales de Alimentación SA - Arki...  AWARDED COMPANY  \n",
       "7                                                 UTE  AWARDED COMPANY  \n",
       "8                        Comahue Seguridad Privada SA  AWARDED COMPANY  \n",
       "9                Líderes Consultores de Seguridad SRL  AWARDED COMPANY  \n",
       "10                                         Ministerio  AWARDED COMPANY  \n",
       "11                                   Custos Seguridad  AWARDED COMPANY  \n",
       "12                                   X Protection SRL  AWARDED COMPANY  \n",
       "13          Cooperativa de Trabajo Cruz de Malta Ltda  AWARDED COMPANY  \n",
       "14                                      Borguards SRL  AWARDED COMPANY  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370d0ec-78f7-44f1-a8bc-1878e0c2cf84",
   "metadata": {},
   "source": [
    "A simple vista, podemos observar que el modelo reconoció entidades de forma incorrecta, mayormente. En muchos casos, la palabra \"Ministerio\" la reconoció como una empresa adjudicataria, cuando en realidad siquiera debería haber sido considerada. Como explicaremos en la conclusión, consideramos que esto se debe a la poca cantidad de data utilizada para entrenar nuestro modelo.\n",
    "\n",
    "De todos modos, continuemos explorando este nuevo DataFrame. Realizaremos un agrupamiento de nuestra data por la columna \"Type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffe2aeac-4b04-48db-8e2f-803ea282ab53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AWARDED COMPANY</th>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOTIVO</th>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Text\n",
       "Type                 \n",
       "AWARDED COMPANY  2402\n",
       "MOTIVO           1335"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.groupby('Type')[['Text']].count().sort_values(by='Text', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318adf7-cec5-4a42-af21-47473aa22306",
   "metadata": {},
   "source": [
    "Luego generaremos una nueva columna de forma de agrupar solo aquellos reconocimientos con un score mayor al 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f87fa76-6544-426a-ab2d-92a6a27ff84c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in df_2.iterrows():\n",
    "    if row['Score'] > 0.90:\n",
    "        df_2.at[index, 'Agrup'] = 'Mayor al 90%'\n",
    "    else:\n",
    "        df_2.at[index, 'Agrup'] = 'Menor al 90%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd4c1a5-f6f0-45be-987b-1c71df9294c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_3 = df_2[df_2['Agrup'] == 'Mayor al 90%']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b9dbc-4bc9-4cbc-a7b1-3b36a31ceddf",
   "metadata": {},
   "source": [
    "Agrupamos nuestra data primero por texto (o la entidad en sí misma) y luego por tipo de entidad y entidad, contando la cantidad de veces que aparecen en nuestro DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d950bd94-a159-44c6-9e6c-b690377c144f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RESOLUCIÓN N.°</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESOLUCIÓN N.º</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.buenosairescompras.gob.ar</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISPOSICIÓN N.°</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MINISTERIO DE SALUD</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANEXOQue</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mantelectric ICISA</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SECRETARIO DE TRANSPORTE</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE LA CIUDAD AUTÓNOMA DE BUENOS AIRES</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISPOSICIÓN CONJUNTA N.°</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Type\n",
       "Text                                       \n",
       "RESOLUCIÓN N.°                           93\n",
       "RESOLUCIÓN N.º                           66\n",
       "www.buenosairescompras.gob.ar            49\n",
       "DISPOSICIÓN N.°                          38\n",
       "MINISTERIO DE SALUD                      37\n",
       "ANEXOQue                                 33\n",
       "Mantelectric ICISA                       32\n",
       "SECRETARIO DE TRANSPORTE                 29\n",
       "DE LA CIUDAD AUTÓNOMA DE BUENOS AIRES    24\n",
       "DISPOSICIÓN CONJUNTA N.°                 22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.groupby('Text')[['Type']].count().sort_values(by='Type', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b5c453f-9a66-4499-8085-70d3828ab451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MOTIVO</th>\n",
       "      <th>RESOLUCIÓN N.°</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESOLUCIÓN N.º</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWARDED COMPANY</th>\n",
       "      <th>www.buenosairescompras.gob.ar</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MOTIVO</th>\n",
       "      <th>DISPOSICIÓN N.°</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MINISTERIO DE SALUD</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AWARDED COMPANY</th>\n",
       "      <th>ANEXOQue</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mantelectric ICISA</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MOTIVO</th>\n",
       "      <th>SECRETARIO DE TRANSPORTE</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE LA CIUDAD AUTÓNOMA DE BUENOS AIRES</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEL ENTE AUTÁRQUICO TEATRO COLÓN</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Score\n",
       "Type            Text                                        \n",
       "MOTIVO          RESOLUCIÓN N.°                            93\n",
       "                RESOLUCIÓN N.º                            66\n",
       "AWARDED COMPANY www.buenosairescompras.gob.ar             49\n",
       "MOTIVO          DISPOSICIÓN N.°                           38\n",
       "                MINISTERIO DE SALUD                       37\n",
       "AWARDED COMPANY ANEXOQue                                  33\n",
       "                Mantelectric ICISA                        32\n",
       "MOTIVO          SECRETARIO DE TRANSPORTE                  29\n",
       "                DE LA CIUDAD AUTÓNOMA DE BUENOS AIRES     24\n",
       "                DEL ENTE AUTÁRQUICO TEATRO COLÓN          22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.groupby(['Type','Text'])[['Score']].count().sort_values(by='Score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3be249-06c1-4b1f-9939-d6bc6ffcb0dd",
   "metadata": {},
   "source": [
    "Puede verse que el modelo ha reconocido las entidades de forma incorrecta, en mayor medida. Para las 10 entidades con más apariciones en nuestro DataFrame, solo una \"Mantelectric ICISA\" fue reconocida de forma adecuada.\n",
    "\n",
    "Sin embargo, probablemente el modelo esté reconociendo cosas que no deberían reconocerse (lo cual es un problema), pero intentaremos certificar que efectivamente esté reconociendo aquellas entidades que sí deberían tenerse en cuenta.\n",
    "\n",
    "Para ello compararemos la extracción manual que en su momento realizamos durante nuestra investigación sobre los Juegos Olímpicos de la Juventud 2018 (YOG 2018). Si bien este DataFrame estará supeditado a aquellas cuestiones vinculadas de forma estricta con este megaevento deportivo, consideramos que es un buen parámetro para entender la capacidad de nuestro modelo en reconocer entidades dentro del Boletín Oficial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4cd23-0445-4e5e-a32c-bc715771c934",
   "metadata": {},
   "source": [
    "Importamos nuestro archivo con la data analizada durante el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e8ed642-53b5-4d2e-8b0b-4b92800c9076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Nro_expediente</th>\n",
       "      <th>Nro_BO</th>\n",
       "      <th>Fecha_BO</th>\n",
       "      <th>Organismo</th>\n",
       "      <th>Descripción</th>\n",
       "      <th>Empresa</th>\n",
       "      <th>Monto_ARS</th>\n",
       "      <th>Monto_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28/06/13</td>\n",
       "      <td>707.752/13</td>\n",
       "      <td>4429</td>\n",
       "      <td>02/07/14</td>\n",
       "      <td>Ministerio de Desarrollo Económico</td>\n",
       "      <td>Puesta en Valor del Polideportivo del Barrio L...</td>\n",
       "      <td>COOPERATIVA DE TRABAJO LA UNION LIMITADA</td>\n",
       "      <td>$ 250,000.00</td>\n",
       "      <td>USD 30,637.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/08/13</td>\n",
       "      <td>3.511.323/13</td>\n",
       "      <td>4429</td>\n",
       "      <td>02/07/14</td>\n",
       "      <td>Ministerio de Desarrollo Económico</td>\n",
       "      <td>Puesta en Valor del Polideportivo del Barrio L...</td>\n",
       "      <td>COOPERATIVA DE TRABAJO LA UNION LIMITADA</td>\n",
       "      <td>$ 150,000.00</td>\n",
       "      <td>USD 18,382.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fecha Nro_expediente  Nro_BO  Fecha_BO  \\\n",
       "0  28/06/13     707.752/13    4429  02/07/14   \n",
       "1  12/08/13   3.511.323/13    4429  02/07/14   \n",
       "\n",
       "                            Organismo  \\\n",
       "0  Ministerio de Desarrollo Económico   \n",
       "1  Ministerio de Desarrollo Económico   \n",
       "\n",
       "                                         Descripción  \\\n",
       "0  Puesta en Valor del Polideportivo del Barrio L...   \n",
       "1  Puesta en Valor del Polideportivo del Barrio L...   \n",
       "\n",
       "                                    Empresa     Monto_ARS      Monto_USD  \n",
       "0  COOPERATIVA DE TRABAJO LA UNION LIMITADA  $ 250,000.00  USD 30,637.25  \n",
       "1  COOPERATIVA DE TRABAJO LA UNION LIMITADA  $ 150,000.00  USD 18,382.35  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yog = pd.read_csv(\"Consolidado YOG 2012-19.csv\")\n",
    "yog.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e57a3-5fc0-4f9d-8ee2-8c2cd976c8b0",
   "metadata": {},
   "source": [
    "Filtramos todas las anotaciones realizadas para el Boletín Oficial número 5351, del 11 de abril de 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17210e8d-3f82-44c1-9ba9-a5c58cceeb67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Nro_expediente</th>\n",
       "      <th>Nro_BO</th>\n",
       "      <th>Fecha_BO</th>\n",
       "      <th>Organismo</th>\n",
       "      <th>Descripción</th>\n",
       "      <th>Empresa</th>\n",
       "      <th>Monto_ARS</th>\n",
       "      <th>Monto_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11/04/18</td>\n",
       "      <td>04.608.204- MGEYA-UPEJOL/18</td>\n",
       "      <td>5351</td>\n",
       "      <td>11/04/18</td>\n",
       "      <td>Ministerio de Modernización, Innovación y Tecn...</td>\n",
       "      <td>Contratación de Patrocinio Local para los Jueg...</td>\n",
       "      <td>PISTRELLI, HENRY MARTIN Y ASOCIADOS SRL</td>\n",
       "      <td>$ 4,145,280.00</td>\n",
       "      <td>USD 203,200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>27/03/18</td>\n",
       "      <td>EX-2018-02461482-MGEYA-IVC</td>\n",
       "      <td>5351</td>\n",
       "      <td>11/04/18</td>\n",
       "      <td>Instituto de la Vivienda de la Ciudad de Bueno...</td>\n",
       "      <td>Contratación de Saneamiento, Mantenimiento y R...</td>\n",
       "      <td>COOPERATIVA DE TRABAJO ECOLOGICA ARGENTINA LTDA</td>\n",
       "      <td>$ 6,037,751.50</td>\n",
       "      <td>USD 295,968.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fecha               Nro_expediente  Nro_BO  Fecha_BO  \\\n",
       "10   11/04/18  04.608.204- MGEYA-UPEJOL/18    5351  11/04/18   \n",
       "242  27/03/18   EX-2018-02461482-MGEYA-IVC    5351  11/04/18   \n",
       "\n",
       "                                             Organismo  \\\n",
       "10   Ministerio de Modernización, Innovación y Tecn...   \n",
       "242  Instituto de la Vivienda de la Ciudad de Bueno...   \n",
       "\n",
       "                                           Descripción  \\\n",
       "10   Contratación de Patrocinio Local para los Jueg...   \n",
       "242  Contratación de Saneamiento, Mantenimiento y R...   \n",
       "\n",
       "                                             Empresa       Monto_ARS  \\\n",
       "10           PISTRELLI, HENRY MARTIN Y ASOCIADOS SRL  $ 4,145,280.00   \n",
       "242  COOPERATIVA DE TRABAJO ECOLOGICA ARGENTINA LTDA  $ 6,037,751.50   \n",
       "\n",
       "          Monto_USD  \n",
       "10   USD 203,200.00  \n",
       "242  USD 295,968.21  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yog.loc[yog['Nro_BO'] == 5351]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9231b-76f0-4b8c-98fe-4871f7839441",
   "metadata": {},
   "source": [
    "Puede verse que hay solo dos filas con información respectiva a los YOG 2018 dentro de ese boletín. En nuestra data no hemos siquiera podido reconocer el importe, pero sí el nombre de la empresa. Intentaremos buscar en nuestra data si encontró a estas dos empresas dentro de las más de 3.000 filas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd1d16d-1a2c-447b-9b39-475a31736a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_2[(df_2['Text'] == 'Pistrelli') | (df_2['Text'] == 'Ecologica Argentina')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4e512b4-87f1-4f19-a4c4-eb6372239abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "      <th>Agrup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.955421</td>\n",
       "      <td>Ecologica Argentina</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "      <td>Mayor al 90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>Pistrelli</td>\n",
       "      <td>AWARDED COMPANY</td>\n",
       "      <td>Mayor al 90%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BeginOffset  EndOffset     Score                 Text             Type  \\\n",
       "2262            0         19  0.955421  Ecologica Argentina  AWARDED COMPANY   \n",
       "2991           21         30  0.925592            Pistrelli  AWARDED COMPANY   \n",
       "\n",
       "             Agrup  \n",
       "2262  Mayor al 90%  \n",
       "2991  Mayor al 90%  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2[(df_2['Text'].str.contains('Pistrelli', case=False)) | (df_2['Text'].str.contains('Ecologica', case=False))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb7ecb-25c4-473b-96cf-9d14473b3f78",
   "metadata": {},
   "source": [
    "Se puede observar que las dos entidades fueron reconocidas como compañías adjudicatarias, pero en ambos casos el nombre figura recortado. Si bien la asignación con el tipo de entidad fue la adecuada, deberemos inspeccionar aún más para hacer de este modelo una herramienta de detección confiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5053c0d1-226d-4a50-809d-7e783e7029b9",
   "metadata": {},
   "source": [
    "### Conclusiones y comentarios de cara al trabajo de tesis:\n",
    "\n",
    "<ol>\n",
    "    <li>Incorporar dentro del moldeo de la data de input la posibilidad de trabajar con un archivo de texto sin saltos de línea, ya que en el ejercicio de etiquetado de la data se ha observado que muchas veces las oraciones llegan partidas y eso dificulta la asociación con las entidades.</li>\n",
    "    <li>Lógicamente, utilizar corpus de texto más extensos, a los fines de mejorar el ejercicio de predicción de nuestro modelo. En este caso, hemos decidido hacerlo con un archivo más pequeño debido a la falta de tiempo en la implementación y a que el objetivo principal era dejar operativo el modelo.</li>\n",
    "    <li>Implementar otro tipo de approachs frente al mismo problema, por ejemplo, redes neuronales con transformadores. Hay soluciones que pueden ser de soporte, como <a href=\"https://www.github.com/AymurAI/dev.git\"> AymurAI</a> o <a href=\"https://github.com/MuckRock/sidekick\"> Sidekick</a>.</li>\n",
    "    <li> Se podría inspeccionar, también, en la creación de una base SQL dentro de AWS, como podría ser  Amazon RDS, para realizar analítica y Quicksight, para almacenar las métricas y generar visualizaciones sobre los datos más importantes. </li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
